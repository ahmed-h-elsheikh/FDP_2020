{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Run in google colab](https://colab.research.google.com/github/ahmed-h-elsheikh/FDP_2020/blob/master/UQ_v2.ipynb)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rc('text', usetex=True)\n",
    "import matplotlib\n",
    "font = {'size'   : 18}\n",
    "matplotlib.rc('font', **font)\n",
    "# plt.style.use('seaborn-white')\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import random as rand\n",
    "from scipy import stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following are helper functions -- generally these should be used as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScI-VEK9Zphb"
   },
   "outputs": [],
   "source": [
    "def data_describe(x):\n",
    "    [min_value, p_1, p_10, p_50, p_90, p_99, max_value] = np.percentile(x, [0, 1, 10, 50, 90, 99, 100])\n",
    "    print('========================')\n",
    "    print('Number of Monte Carlo Samples: {:d}'.format(len(x)))\n",
    "    print('========================')\n",
    "    print('min    : {:.7e}'.format(min_value))\n",
    "    print('max    : {:.7e}'.format(max_value))\n",
    "    print('mean   : {:.7e}'.format(x.mean()))\n",
    "    print('median : {:.7e}'.format(np.median(x)))\n",
    "\n",
    "    print('std    : {:.7e}'.format(x.std()))\n",
    "    print('========================')\n",
    "    print('Data percentiles')\n",
    "    print('P1  : {:.7e}'.format(p_1))\n",
    "    print('P10 : {:.7e}'.format(p_10))\n",
    "    print('P50 : {:.7e}'.format(p_50))\n",
    "    print('P90 : {:.7e}'.format(p_90))\n",
    "    print('P99 : {:.7e}'.format(p_99))\n",
    "    print('========================')\n",
    "\n",
    "def sensitivity_analysis(df, figsize=None, xlabel='Data'):\n",
    "    min_value = np.inf\n",
    "    max_value = -np.inf\n",
    "    n_subfigures = len(df.columns)\n",
    "    if figsize is None:\n",
    "        figsize=(8,5*n_subfigures)\n",
    "    fig, axs = plt.subplots(n_subfigures, 1, sharex=False, figsize=figsize)\n",
    "    sensitivity_df = df.copy()\n",
    "    for idx_ , col_ in enumerate(df.columns):\n",
    "        temp_df = df.copy()\n",
    "        for temp_col_ in temp_df.columns:\n",
    "            if temp_col_ == col_:\n",
    "                continue\n",
    "            temp_df[temp_col_] = temp_df[temp_col_].mean()\n",
    "        # perform the calculations on temp_df\n",
    "        temp_STOIIP = calculate_STOIIP(temp_df)\n",
    "        sensitivity_df[col_] = temp_STOIIP\n",
    "        min_value_ = temp_STOIIP.min()\n",
    "        max_value_ = temp_STOIIP.max()\n",
    "        if min_value_ < min_value:\n",
    "            min_value = min_value_\n",
    "        if max_value_ > max_value:\n",
    "            max_value = max_value_\n",
    "           \n",
    "        plot_distribution(temp_STOIIP, axs=axs[idx_], xlabel='{}--{}'.format(xlabel, col_))\n",
    "        print('Sensitivity_analysis for {}--{}'.format(xlabel, col_))\n",
    "        data_describe(temp_STOIIP)\n",
    "\n",
    "        #axs[idx_].axvline(x=temp_STOIIP.mean(), color='r')\n",
    "        #axs[idx_].axvline(x=temp_STOIIP.min(), color='b')\n",
    "        #axs[idx_].axvline(x=temp_STOIIP.max(), color='b')\n",
    "    slack_value = (max_value-min_value)/20 \n",
    "    for idx_ , col_ in enumerate(df.columns):\n",
    "        axs[idx_].set_xlim([min_value - slack_value, max_value + slack_value])\n",
    "    plt.show()\n",
    "\n",
    "    return sensitivity_df\n",
    "\n",
    "def ordered_boxplot(sensitivity_df, xlabel='Data'):\n",
    "    variations_np = []\n",
    "    min_value = np.inf\n",
    "    max_value = -np.inf\n",
    "\n",
    "    for column_ in sensitivity_df.columns:\n",
    "        [p_0, p_10, p_90, p_100] = np.percentile(sensitivity_df[column_].values, [0, 10, 90, 100])\n",
    "        data_variation = p_90-p_10\n",
    "        variations_np.append(data_variation)\n",
    "        if p_0 < min_value:\n",
    "            min_value = p_0\n",
    "        if p_100 > max_value:\n",
    "            max_value = p_100\n",
    "\n",
    "    variations_np = np.array(variations_np)\n",
    "    sort_index = np.argsort(variations_np)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1, tight_layout=True, figsize=(12, 6))\n",
    "    new_median = sensitivity_df.mean(axis=0).values\n",
    "    sensitivity_df2 = sensitivity_df.iloc[:, sort_index] \n",
    "    # axs.boxplot(sensitivity_df2.values, labels=sensitivity_df2.columns, usermedians=new_median, whis=[0, 100], vert=False)\n",
    "    axs.boxplot(sensitivity_df2.values, labels=sensitivity_df2.columns, usermedians=new_median, whis=[10, 90], vert=False)\n",
    "    # axs.boxplot(sensitivity_df2.values, labels=sensitivity_df2.columns, usermedians=new_median, vert=False)\n",
    "\n",
    "    axs.axvline(x=sensitivity_df2.iloc[:,0].mean(), color='r', linewidth=2)\n",
    "    axs.grid(alpha=0.75)\n",
    "    # boxplot = sensitivity_df.boxplot()\n",
    "    # parts = axs.violinplot(\n",
    "    #         sensitivity_df, showmeans=False, showmedians=False,\n",
    "    #         showextrema=False)\n",
    "    slack_value = (max_value-min_value)/20 \n",
    "    axs.set_xlim([min_value - slack_value, max_value + slack_value])\n",
    "    axs.set_xlabel(xlabel)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_distribution(x, axs=None, xlim=None, ylim=None, figsize_=(15,8), bins_=100, kde_=True, cumulative_=False, xlabel='Distribution'):\n",
    "    # plot the data\n",
    "    if axs == None:\n",
    "        fig, axs = plt.subplots(figsize=figsize_)\n",
    "    axs.hist(x, density=False, bins=bins_, facecolor='b', alpha=0.5)\n",
    "    axs.grid(alpha=0.75)\n",
    "    axs.set_xlabel(xlabel)\n",
    "    axs.set_ylabel('Count')\n",
    "    # axs.set_title('Histogram plot of a random variable')\n",
    "\n",
    "    # axs.set_xlim([x.min(), x.max()])\n",
    "    if xlim:\n",
    "        x_min, x_max = xlim\n",
    "    else:\n",
    "        x_min, x_max = axs.get_xlim()\n",
    "    if ylim:\n",
    "        y_min, y_max = ylim\n",
    "    else:\n",
    "        y_min, y_max = axs.get_ylim()\n",
    "    axs.set_xlim([x_min, x_max])\n",
    "    axs.set_ylim([y_min, y_max])\n",
    "    # axs.yaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%.3e'))\n",
    "\n",
    "\n",
    "def plot_ecdf(x, axs=None, xlim=None, ylim=None, figsize_=(15,8), bins_=100, xlabel='Data'):\n",
    "    if axs == None:\n",
    "        fig, axs = plt.subplots(figsize=figsize_)\n",
    "    axs.hist(x,cumulative=True, density=True, bins=bins_, alpha=0.5)\n",
    "    # plt.text(60, .025, '$P_{10}={:e},\\\\ P_{50}={:e},\\\\ P_90={:e}$'.format(p_10, p_50, p_90))\n",
    "    axs.grid(alpha=0.75)\n",
    "    axs.set_xlabel(xlabel)\n",
    "    axs.set_ylabel('ECDF')\n",
    "    axs.set_title('Empirical distribution function plot')\n",
    "    \n",
    "    if xlim:\n",
    "        x_min, x_max = xlim\n",
    "    else:\n",
    "        x_min, x_max = axs.get_xlim()\n",
    "    if ylim:\n",
    "        y_min, y_max = ylim\n",
    "    else:\n",
    "        y_min, y_max = axs.get_ylim()\n",
    "    axs.set_xlim([x_min, x_max])\n",
    "    axs.set_ylim([y_min, y_max])\n",
    "    \n",
    "\n",
    "    str_shift = 0.05\n",
    "    [p_10, p_50, p_90] = np.percentile(x, [10, 50, 90])\n",
    "    \n",
    "    axs.hlines(y=0.1, xmin=x_min, xmax=p_10)\n",
    "    axs.vlines(x=p_10, ymin=0, ymax=0.1)\n",
    "    text_str = \"$P_{10}=\" + \"{:.3e}\".format(p_10) + \"$\"\n",
    "    plt.text(p_10, 0.1+str_shift, text_str,\n",
    "             {'color': 'black', 'fontsize': 18, 'ha': 'center', 'va': 'center'})\n",
    "    # 'bbox': dict(boxstyle=\"round\", fc=\"white\", ec=\"black\", pad=0.5)})\n",
    "\n",
    "    axs.hlines(y=0.5, xmin=x_min, xmax=p_50)\n",
    "    axs.vlines(x=p_50, ymin=0, ymax=0.5)\n",
    "    text_str = \"$P_{50}=\" + \"{:.3e}\".format(p_50) + \"$\"\n",
    "    plt.text(p_50, 0.5+str_shift, text_str,\n",
    "             {'color': 'black', 'fontsize': 18, 'ha': 'center', 'va': 'center'})\n",
    "\n",
    "    axs.hlines(y=0.9, xmin=x_min, xmax=p_90)\n",
    "    axs.vlines(x=p_90, ymin=0, ymax=0.9)\n",
    "    text_str = \"$P_{90}=\" + \"{:.3e}\".format(p_90) + \"$\"\n",
    "    plt.text(p_90, 0.9+str_shift, text_str,\n",
    "             {'color': 'black', 'fontsize': 18, 'ha': 'center', 'va': 'center'})\n",
    "\n",
    "    axs.yaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%.3f'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpxapiiZZphi"
   },
   "outputs": [],
   "source": [
    "# number of Monte Carlo samples\n",
    "# use the same for all Random Variables\n",
    "n_samples = 1e6\n",
    "n_samples = np.int64(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "pptzRBMHZphn",
    "outputId": "b9fcd46a-aeef-4116-c201-7cf30d653ce6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# random numbers from uniform distribution\n",
    "lower_limit = 10\n",
    "upper_limit = 20\n",
    "x_uniform = rand.uniform(low=lower_limit, high=upper_limit, size=n_samples)\n",
    "plot_distribution(x_uniform,figsize_=(8,5), xlim=[lower_limit, upper_limit])\n",
    "plot_ecdf(x_uniform, figsize_=(8,5), xlim=[lower_limit, upper_limit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "KV5Ec8ouZpht",
    "outputId": "1c1cd56c-cb1d-48cc-b7d4-f4d973f3eb35"
   },
   "outputs": [],
   "source": [
    "# generate random numbers from N(0,1)\n",
    "x_mean = 0\n",
    "x_std = 1\n",
    "x_normal = rand.normal(loc=x_mean, scale=x_std, size=n_samples)\n",
    "plot_distribution(x_normal,figsize_=(8,5))\n",
    "plot_ecdf(x_normal, figsize_=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "colab_type": "code",
    "id": "Yn8-jQsiZphy",
    "outputId": "dfe88599-92f6-4d81-c652-0ee966157113"
   },
   "outputs": [],
   "source": [
    "# generate log-normal random variable  --> always positive because it is exponential of Normal random variable \n",
    "# this distribution is defined in \n",
    "log_x_mean = 2\n",
    "log_x_std = 1\n",
    "x_lognormal = rand.lognormal(mean=log_x_mean, sigma=log_x_std, size=n_samples)\n",
    "plot_distribution(x_lognormal,figsize_=(8,5), xlim=[0, 100])\n",
    "plot_ecdf(x_lognormal, figsize_=(8,5), xlim=[0, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logarithm of lognormal should be a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot the logarithm of the distribution')\n",
    "plot_distribution(np.log(x_lognormal),figsize_=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "xrNnny6FZph3",
    "outputId": "a2af1115-608e-49b1-f474-8c470d91801a"
   },
   "outputs": [],
   "source": [
    "# generate random numbers from a triangular distribution\n",
    "x_low = 0\n",
    "x_mode = 7\n",
    "x_high = 10\n",
    "x_tri = rand.triangular(left=x_low, mode=x_mode, right=x_high, size=n_samples)\n",
    "plot_distribution(x_tri,figsize_=(8,5), xlim=[x_low, x_high])\n",
    "plot_ecdf(x_tri, figsize_=(8,5), xlim=[x_low, x_high])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following is a specific example for STOIIP calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfzWQuPuZph7"
   },
   "outputs": [],
   "source": [
    "# 1- define data distributions\n",
    "Bo = rand.uniform(low=1.19, high=1.21, size=n_samples) # units Bbl/STB\n",
    "Sw = rand.uniform(low=0.19, high=0.45, size=n_samples)\n",
    "porosity = rand.triangular(left=0.17, mode=0.213, right=0.24, size=n_samples)\n",
    "GRV = rand.triangular(left=0.55, mode=0.64, right=0.72, size=n_samples) # units 10^9 m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- put your data into named tuples in a pandas.DataFrame \n",
    "data_df = pd.DataFrame()\n",
    "data_df['GRV'] = GRV\n",
    "data_df['porosity'] = porosity\n",
    "data_df['Sw'] = Sw\n",
    "data_df['Bo'] = Bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- define your calculation inside a function with data\n",
    "# http://www.oilfieldwiki.com/wiki/Oil_in_place\n",
    "# perform Monte Carlo simulation on the random variables \n",
    "# define the calculations needed\n",
    "def calculate_STOIIP(data_df):\n",
    "    STOIIP = 7758 * (data_df['GRV'] * 1e9) * data_df['porosity']  * (1 - data_df['Sw']) / data_df['Bo'] # units barrels\n",
    "    return STOIIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-j9oHQlZph-"
   },
   "outputs": [],
   "source": [
    "# perform analysis\n",
    "t0 = time.time()\n",
    "STOIIP = calculate_STOIIP(data_df)\n",
    "\n",
    "print('finished MC calucation of STOIIP in {} sec'.format(time.time()-time.time()))\n",
    "data_describe(STOIIP)\n",
    "plot_distribution(STOIIP, figsize_=(10,5), xlabel='STOIIP')\n",
    "plot_ecdf(STOIIP, figsize_=(10,5), xlabel='STOIIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3M6yAX8dZpiK",
    "outputId": "0d3f087d-6c1a-479e-e1af-504621a84fdb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sensitivity_df = sensitivity_analysis(data_df, figsize=(12,6*5), xlabel='STOIIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LsCehnsiZpiR"
   },
   "outputs": [],
   "source": [
    "ordered_boxplot(sensitivity_df, xlabel='STOIIP')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "UQ_v0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
